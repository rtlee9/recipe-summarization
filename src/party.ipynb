{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cocktail Title generator\n",
    "##### By: Mystery Machine\n",
    "Just enter the names of the ingredients, instructions to prepare and BOOM!\n",
    "Our model will predict a few unheard-of names for your cocktail!ðŸ˜‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load predict.py\n",
    "\"\"\"Predict a title for a recipe.\"\"\"\n",
    "from os import path\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "from utils import str_shape\n",
    "import keras.backend as K\n",
    "import argparse\n",
    "\n",
    "from config import path_models, path_data\n",
    "from constants import FN1, FN0, nb_unknown_words, eos\n",
    "from model import create_model\n",
    "from sample_gen import gensamples\n",
    "\n",
    "# set seeds in random libraries\n",
    "seed = 42\n",
    "\n",
    "#random.seed(seed)\n",
    "#np.random.seed(seed)\n",
    "\n",
    "\n",
    "def load_weights(model, filepath):\n",
    "    \"\"\"Load all weights possible into model from filepath.\n",
    "\n",
    "    This is a modified version of keras load_weights that loads as much as it can\n",
    "    if there is a mismatch between file and model. It returns the weights\n",
    "    of the first layer in which the mismatch has happened\n",
    "    \"\"\"\n",
    "    print('Loading', filepath, 'to', model.name)\n",
    "    with h5py.File(filepath, mode='r') as f:\n",
    "        # new file format\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "\n",
    "        # we batch weight value assignments in a single backend call\n",
    "        # which provides a speedup in TensorFlow.\n",
    "        weight_value_tuples = []\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            g = f[name]\n",
    "            weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "            if len(weight_names):\n",
    "                weight_values = [g[weight_name] for weight_name in weight_names]\n",
    "                try:\n",
    "                    layer = model.get_layer(name=name)\n",
    "                except:\n",
    "                    layer = None\n",
    "                if not layer:\n",
    "                    print('failed to find layer', name, 'in model')\n",
    "                    print('weights', ' '.join(str_shape(w) for w in weight_values))\n",
    "                    print('stopping to load all other layers')\n",
    "                    weight_values = [np.array(w) for w in weight_values]\n",
    "                    break\n",
    "                symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
    "                weight_value_tuples += zip(symbolic_weights, weight_values)\n",
    "                weight_values = None\n",
    "        K.batch_set_value(weight_value_tuples)\n",
    "    return weight_values\n",
    "\n",
    "\n",
    "def main(sample_str=None):\n",
    "    \"\"\"Predict a title for a recipe.\"\"\"\n",
    "    # load model parameters used for training\n",
    "    with open(path.join(path_models, 'model_params.json'), 'r') as f:\n",
    "        model_params = json.load(f)\n",
    "\n",
    "    # create placeholder model\n",
    "    model = create_model(**model_params)\n",
    "\n",
    "    # load weights from training run\n",
    "    load_weights(model, path.join(path_models, '{}.hdf5'.format(FN1)))\n",
    "\n",
    "    # load recipe titles and descriptions\n",
    "    with open(path.join(path_data, 'vocabulary-embedding.data.pkl'), 'rb') as fp:\n",
    "        X_data, Y_data = pickle.load(fp)\n",
    "\n",
    "    # load vocabulary\n",
    "    with open(path.join(path_data, '{}.pkl'.format(FN0)), 'rb') as fp:\n",
    "        embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "    vocab_size, embedding_size = embedding.shape\n",
    "    oov0 = vocab_size - nb_unknown_words\n",
    "\n",
    "    if sample_str is None:\n",
    "        # load random recipe description if none provided\n",
    "        i = np.random.randint(len(X_data))\n",
    "        sample_str = ''\n",
    "        sample_title = ''\n",
    "        for w in X_data[i]:\n",
    "            sample_str += idx2word[w] + ' '\n",
    "        for w in Y_data[i]:\n",
    "            sample_title += idx2word[w] + ' '\n",
    "        y = Y_data[i]\n",
    "        print('Randomly sampled recipe:')\n",
    "        print(\"blah\",sample_title)\n",
    "        print(\"power\",sample_str)\n",
    "    else:\n",
    "        sample_title = ''\n",
    "        y = [eos]\n",
    "\n",
    "    x = [word2idx[w.rstrip('^')] for w in sample_str.split()]\n",
    "\n",
    "    samples = gensamples(\n",
    "        skips=2,\n",
    "        k=1,\n",
    "        batch_size=2,\n",
    "        short=False,\n",
    "        temperature=1.,\n",
    "        use_unk=True,\n",
    "        model=model,\n",
    "        data=(x, y),\n",
    "        idx2word=idx2word,\n",
    "        oov0=oov0,\n",
    "        glove_idx2idx=glove_idx2idx,\n",
    "        vocab_size=vocab_size,\n",
    "        nb_unknown_words=nb_unknown_words,\n",
    "    )\n",
    "\n",
    "    headline = samples[0][0][len(samples[0][1]):]\n",
    "    ' '.join(idx2word[w] for w in headline)\n",
    "\n",
    "\n",
    "def callme(randomstr):\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--sample-str', type=str, default=None, help='Sample recipe description')\n",
    "    # args = parser.parse_args()\n",
    "    # sample_str=args.sample_str\n",
    "    main(randomstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/dhruv/PycharmProjects/recipe/recipe-summarization/models/train.hdf5 to sequential_9\n",
      "embedding_1\n",
      "lstm_1\n",
      "dropout_1\n",
      "lstm_2\n",
      "dropout_2\n",
      "lstm_3\n",
      "dropout_3\n",
      "simplecontext_1\n",
      "timedistributed_1\n",
      "failed to find layer timedistributed_1 in model\n",
      "weights 944x2464 2464\n",
      "stopping to load all other layers\n",
      "HEAD: <eos>\n",
      "DESC: vodka ; beer ; sugar ; lime ; Stir all ingredients with ice and strain into a big cocktail glass . Add the sugar on the top and serve\n",
      "HEADS:\n",
      "113.12955951690674 great Crown shcvings final 6 ingrediants Bible 8 jÃ¤germeister crÃ¨me prevent balance Boomerang Long ;Simply\n",
      "115.65303945541382 Miami SLAM Liquer New but Dash orgeat stay granulated packs glycerine nuts Acapulco apricot preferably\n",
      "[536, 1243, 1827, 1834, 505, 1311, 1137, 1900, 405, 2164, 1023, 1791, 1924, 373, 1619]\n"
     ]
    }
   ],
   "source": [
    "#Party here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenvironment3",
   "language": "python",
   "name": "virtualenvironment3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
